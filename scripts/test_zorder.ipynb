{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edb8b2f-f6e1-4b35-9519-0e3853beea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/data2/jaehyeok/dev/ddpm/space-filling-pytorch\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624c98b4-aba9-41ea-818c-244711002c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e1a73d-bccf-406b-97dd-bdf836c5c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.set_device(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7332fa82-0a21-4446-b87d-342bcc2c58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Octree-based Sparse Convolutional Neural Networks\n",
    "# Copyright (c) 2022 Peng-Shuai Wang <wangps@hotmail.com>\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Peng-Shuai Wang\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "class KeyLUT:\n",
    "    def __init__(self):\n",
    "        r256 = torch.arange(256, dtype=torch.int64)\n",
    "        r512 = torch.arange(512, dtype=torch.int64)\n",
    "        zero = torch.zeros(256, dtype=torch.int64)\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "        self._encode = {\n",
    "            device: (\n",
    "                self.xyz2key(r256, zero, zero, 8),\n",
    "                self.xyz2key(zero, r256, zero, 8),\n",
    "                self.xyz2key(zero, zero, r256, 8),\n",
    "            )\n",
    "        }\n",
    "        self._decode = {device: self.key2xyz(r512, 9)}\n",
    "\n",
    "    def encode_lut(self, device=torch.device(\"cpu\")):\n",
    "        if device not in self._encode:\n",
    "            cpu = torch.device(\"cpu\")\n",
    "            self._encode[device] = tuple(e.to(device) for e in self._encode[cpu])\n",
    "        return self._encode[device]\n",
    "\n",
    "    def decode_lut(self, device=torch.device(\"cpu\")):\n",
    "        if device not in self._decode:\n",
    "            cpu = torch.device(\"cpu\")\n",
    "            self._decode[device] = tuple(e.to(device) for e in self._decode[cpu])\n",
    "        return self._decode[device]\n",
    "\n",
    "    def xyz2key(self, x, y, z, depth):\n",
    "        key = torch.zeros_like(x)\n",
    "        for i in range(depth):\n",
    "            mask = 1 << i\n",
    "            key = key | ((x & mask) << (2 * i + 2)) | ((y & mask) << (2 * i + 1)) | ((z & mask) << (2 * i + 0))\n",
    "        return key\n",
    "\n",
    "    def key2xyz(self, key, depth):\n",
    "        x = torch.zeros_like(key)\n",
    "        y = torch.zeros_like(key)\n",
    "        z = torch.zeros_like(key)\n",
    "        for i in range(depth):\n",
    "            x = x | ((key & (1 << (3 * i + 2))) >> (2 * i + 2))\n",
    "            y = y | ((key & (1 << (3 * i + 1))) >> (2 * i + 1))\n",
    "            z = z | ((key & (1 << (3 * i + 0))) >> (2 * i + 0))\n",
    "        return x, y, z\n",
    "\n",
    "\n",
    "_key_lut = KeyLUT()\n",
    "\n",
    "\n",
    "def xyz2key(\n",
    "    x: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    z: torch.Tensor,\n",
    "    b: Optional[Union[torch.Tensor, int]] = None,\n",
    "    depth: int = 16,\n",
    "):\n",
    "    r\"\"\"Encodes :attr:`x`, :attr:`y`, :attr:`z` coordinates to the shuffled keys\n",
    "    based on pre-computed look up tables. The speed of this function is much\n",
    "    faster than the method based on for-loop.\n",
    "\n",
    "    Args:\n",
    "      x (torch.Tensor): The x coordinate.\n",
    "      y (torch.Tensor): The y coordinate.\n",
    "      z (torch.Tensor): The z coordinate.\n",
    "      b (torch.Tensor or int): The batch index of the coordinates, and should be\n",
    "          smaller than 32768. If :attr:`b` is :obj:`torch.Tensor`, the size of\n",
    "          :attr:`b` must be the same as :attr:`x`, :attr:`y`, and :attr:`z`.\n",
    "      depth (int): The depth of the shuffled key, and must be smaller than 17 (< 17).\n",
    "    \"\"\"\n",
    "\n",
    "    EX, EY, EZ = _key_lut.encode_lut(x.device)\n",
    "    x, y, z = x.long(), y.long(), z.long()\n",
    "\n",
    "    mask = 255 if depth > 8 else (1 << depth) - 1\n",
    "    key = EX[x & mask] | EY[y & mask] | EZ[z & mask]\n",
    "    if depth > 8:\n",
    "        mask = (1 << (depth - 8)) - 1\n",
    "        key16 = EX[(x >> 8) & mask] | EY[(y >> 8) & mask] | EZ[(z >> 8) & mask]\n",
    "        key = key16 << 24 | key\n",
    "\n",
    "    if b is not None:\n",
    "        b = b.long()\n",
    "        key = b << 48 | key\n",
    "\n",
    "    return key\n",
    "\n",
    "\n",
    "def key2xyz(key: torch.Tensor, depth: int = 16):\n",
    "    r\"\"\"Decodes the shuffled key to :attr:`x`, :attr:`y`, :attr:`z` coordinates\n",
    "    and the batch index based on pre-computed look up tables.\n",
    "\n",
    "    Args:\n",
    "      key (torch.Tensor): The shuffled key.\n",
    "      depth (int): The depth of the shuffled key, and must be smaller than 17 (< 17).\n",
    "    \"\"\"\n",
    "\n",
    "    DX, DY, DZ = _key_lut.decode_lut(key.device)\n",
    "    x, y, z = torch.zeros_like(key), torch.zeros_like(key), torch.zeros_like(key)\n",
    "\n",
    "    b = key >> 48\n",
    "    key = key & ((1 << 48) - 1)\n",
    "\n",
    "    n = (depth + 2) // 3\n",
    "    for i in range(n):\n",
    "        k = key >> (i * 9) & 511\n",
    "        x = x | (DX[k] << (i * 3))\n",
    "        y = y | (DY[k] << (i * 3))\n",
    "        z = z | (DZ[k] << (i * 3))\n",
    "\n",
    "    return x, y, z, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9089bdcf-d506-4705-9dc6-12e4abec1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch as th\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from torchtyping import TensorType\n",
    "\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=[\n",
    "        # triton.Config({\"BLOCK_SIZE\": 32}),\n",
    "        # triton.Config({\"BLOCK_SIZE\": 64}),\n",
    "        # triton.Config({\"BLOCK_SIZE\": 128}),\n",
    "        triton.Config({\"BLOCK_SIZE\": 256}),\n",
    "        # triton.Config({\"BLOCK_SIZE\": 512}),\n",
    "        # triton.Config({\"BLOCK_SIZE\": 1024}),\n",
    "    ],\n",
    "    key=[\"BN\"],\n",
    ")\n",
    "@triton.jit\n",
    "def point_to_zorder_3d_depth16_fp32_kernel(\n",
    "    xyz_ptr,\n",
    "    distance_ptr,\n",
    "    BN,\n",
    "    space_size,\n",
    "    x_offset,\n",
    "    y_offset,\n",
    "    z_offset,\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    # load data\n",
    "    pid = tl.program_id(0)\n",
    "    idx_bn = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = idx_bn < BN\n",
    "    # TODO no coalescing\n",
    "    fx = tl.load(xyz_ptr + idx_bn * 3 + x_offset, mask=mask)\n",
    "    fy = tl.load(xyz_ptr + idx_bn * 3 + y_offset, mask=mask)\n",
    "    fz = tl.load(xyz_ptr + idx_bn * 3 + z_offset, mask=mask)\n",
    "    x = ((fx + 1) / 2 * space_size).to(tl.int64)\n",
    "    y = ((fy + 1) / 2 * space_size).to(tl.int64)\n",
    "    z = ((fz + 1) / 2 * space_size).to(tl.int64)\n",
    "    x = tl.minimum(tl.maximum(x, 0), space_size - 1)\n",
    "    y = tl.minimum(tl.maximum(y, 0), space_size - 1)\n",
    "    z = tl.minimum(tl.maximum(z, 0), space_size - 1)\n",
    "\n",
    "    # calculate z-order\n",
    "    ret = 0\n",
    "    for i in tl.static_range(0, 16):\n",
    "        q = 1 << i\n",
    "        ret |= (x & q) << (2 * i + 2)\n",
    "        ret |= (y & q) << (2 * i + 1)\n",
    "        ret |= (z & q) << (2 * i + 0)\n",
    "\n",
    "    # write results\n",
    "    tl.store(distance_ptr + idx_bn, ret, mask=mask)\n",
    "\n",
    "\n",
    "def point_to_zorder_3d_depth16_fp32(\n",
    "    xyz: TensorType[\"b\", \"n\", 3, th.float32],\n",
    "    space_size: int,\n",
    "    x_offset: int = 0,\n",
    "    y_offset: int = 1,\n",
    "    z_offset: int = 2,\n",
    "):\n",
    "    B, N = xyz.shape[:2]\n",
    "    distance = xyz.new_empty(B, N, dtype=th.int64)\n",
    "    grid = lambda meta: (triton.cdiv(B * N, meta[\"BLOCK_SIZE\"]),)\n",
    "    point_to_zorder_3d_depth16_fp32_kernel[grid](xyz, distance, B * N, space_size, x_offset, y_offset, z_offset)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e190d766-d88f-4447-9c89-90dc053b45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = th.rand(16, 3, device=\"cuda\") * 2 - 1\n",
    "grid_size = 2**16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd36707-ed4b-4321-bb28-48a75fb430c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[142258343134507, 234905236643413, 266121751766580, 229605166709668,\n",
       "         274726867874873, 221983309916557,  34985663610472, 198169605513854,\n",
       "         120898085593575,  54730846400195, 253166080228275, 191542425668609,\n",
       "         249175721684259, 149382059561983, 124312971898722, 247139660076827]],\n",
       "       device='cuda:9')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_order_triton = point_to_zorder_3d_depth16_fp32(xyz[None], grid_size, 0, 1, 2)\n",
    "z_order_triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5125e582-fa6d-4138-a22f-ce92053514e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([142258343134507, 234905236643413, 266121751766580, 229605166709668,\n",
       "        274726867874873, 221983309916557,  34985663610472, 198169605513854,\n",
       "        120898085593575,  54730846400195, 253166080228275, 191542425668609,\n",
       "        249175721684259, 149382059561983, 124312971898722, 247139660076827],\n",
       "       device='cuda:9')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_coord = ((xyz + 1) / 2 * grid_size).long()\n",
    "x, y, z = grid_coord[:, 0].long(), grid_coord[:, 1].long(), grid_coord[:, 2].long()\n",
    "z_order_ptv3 = xyz2key(x, y, z)\n",
    "z_order_ptv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567c6b6b-bdd6-444d-a91d-99629a7e8d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.allclose(z_order_triton, z_order_ptv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387c368-88b7-48ec-a798-6f6f269ac458",
   "metadata": {},
   "source": [
    "# Large Scale Test\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e549f3f-4842-47fb-be03-f270fa9afd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = th.rand(32768, 3, device=\"cuda\") * 2 - 1\n",
    "grid_size = 2**16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "083098df-9afd-43e3-84a1-3888fdcc9ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[138784506524412, 224138053161915, 185899124151734,  ...,\n",
       "           3557457093838,  77484789105525, 249790088739659]], device='cuda:9')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_order_triton = point_to_zorder_3d_depth16_fp32(xyz[None], grid_size, 0, 1, 2)\n",
    "z_order_triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dd4528d-2e03-4117-bae8-00c053ac169e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([138784506524412, 224138053161915, 185899124151734,  ...,\n",
       "          3557457093838,  77484789105525, 249790088739659], device='cuda:9')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_coord = ((xyz + 1) / 2 * grid_size).long()\n",
    "x, y, z = grid_coord[:, 0].long(), grid_coord[:, 1].long(), grid_coord[:, 2].long()\n",
    "z_order_ptv3 = xyz2key(x, y, z)\n",
    "z_order_ptv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c3e2c8-935b-495c-badc-13b841a56eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.allclose(z_order_triton, z_order_ptv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80149f82-6ddc-40b3-808f-22758e91f46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
